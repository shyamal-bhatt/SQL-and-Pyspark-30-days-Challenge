{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    " CREATE TABLE Billing (\n",
    "    id BIGINT,\n",
    "    billing_type STRING NOT NULL,\n",
    "    invoice_date DATE NOT NULL,\n",
    "    currency STRING NOT NULL\n",
    ")\n",
    "USING DELTA;\n",
    "\n",
    "CREATE TABLE product_items (\n",
    "    id BIGINT,\n",
    "    billing_id BIGINT,\n",
    "    product STRING,\n",
    "    amount DECIMAL(10, 2),\n",
    "    type STRING,\n",
    "    valid_from DATE,\n",
    "    valid_to DATE\n",
    ")\n",
    "USING DELTA;\n",
    "\n",
    "CREATE TABLE Exchange (\n",
    "    date DATE NOT NULL,\n",
    "    from_currency STRING NOT NULL,\n",
    "    to_currency STRING NOT NULL,\n",
    "    exchange_rate DECIMAL(10, 5) NOT NULL\n",
    ")\n",
    "USING DELTA;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "INSERT INTO Billing (id, billing_type, invoice_date, currency) VALUES\n",
    "(1, 'invoice', '2019-01-15', 'usd'),\n",
    "(2, 'invoice', '2019-01-15', 'cad'),\n",
    "(3, 'credit_note', '2019-03-15', 'cad'),\n",
    "(4, 'invoice', '2019-03-15', 'eur'),\n",
    "(5, 'invoice', '2019-04-01', 'eur'),\n",
    "(6, 'credit_note', '2019-04-18', 'eur'),\n",
    "(7, 'invoice', '2019-04-18', 'usd'),\n",
    "(8, 'invoice', '2019-05-27', 'usd');\n",
    "\n",
    "INSERT INTO product_items (id, billing_id, product, amount, type, valid_from, valid_to) VALUES\n",
    "(1, 1, 'product1', 11500, 'recurring', '2019-01-15', '2019-12-31'),\n",
    "(2, 1, 'product2', 5000, 'one_shot', NULL, NULL),\n",
    "(3, 2, 'product3', 7893, 'recurring', '2019-01-15', '2020-01-14'),\n",
    "(4, 2, 'product4', 16000, 'recurring', '2019-01-15', '2020-01-14'),\n",
    "(5, 3, 'product3', 7893, 'recurring', '2019-01-15', '2020-01-14'),\n",
    "(6, 3, 'product4', 16000, 'recurring', '2019-01-15', '2020-01-14'),\n",
    "(7, 4, 'product1', 12350, 'recurring', '2019-03-15', '2019-12-31'),\n",
    "(8, 5, 'product2', 5500, 'one_shot', NULL, NULL),\n",
    "(9, 5, 'product3', 9000, 'recurring', '2019-04-01', '2020-03-31'),\n",
    "(10, 5, 'product4', 14321, 'recurring', '2019-04-01', '2020-03-31'),\n",
    "(11, 6, 'product2', 5500, 'one_shot', NULL, NULL),\n",
    "(12, 6, 'product3', 9000, 'recurring', '2019-04-01', '2020-03-31'),\n",
    "(13, 6, 'product4', 14321, 'recurring', '2019-04-01', '2020-03-31'),\n",
    "(14, 7, 'product2', 4050, 'one_shot', NULL, NULL),\n",
    "(15, 8, 'product6', 9000, 'one_shot', NULL, NULL);\n",
    "\n",
    "INSERT INTO Exchange (date, from_currency, to_currency, exchange_rate) VALUES\n",
    "('2019-01-15', 'cad', 'usd', 1.332),\n",
    "('2019-01-15', 'eur', 'usd', 0.978),\n",
    "('2019-01-15', 'usd', 'usd', 1),\n",
    "('2019-03-15', 'cad', 'usd', 1.402),\n",
    "('2019-03-15', 'eur', 'usd', 0.911),\n",
    "('2019-03-15', 'usd', 'usd', 1),\n",
    "('2019-04-01', 'cad', 'usd', 1.360),\n",
    "('2019-04-01', 'eur', 'usd', 0.947),\n",
    "('2019-04-01', 'usd', 'usd', 1),\n",
    "('2019-04-18', 'cad', 'usd', 1.319),\n",
    "('2019-04-18', 'eur', 'usd', 0.966),\n",
    "('2019-04-18', 'usd', 'usd', 1),\n",
    "('2019-05-27', 'cad', 'usd', 1.388),\n",
    "('2019-05-27', 'eur', 'usd', 0.932),\n",
    "('2019-05-27', 'usd', 'usd', 1);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annual Recurring Revenue (ARR) as of a specific date (2020-01-28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import col, datediff, round, sum as spark_sum\n",
    "\n",
    "# Load the Delta tables\n",
    "billing_df = spark.table(\"default.billing\")\n",
    "product_item_df = spark.table(\"default.product_items\")\n",
    "exchange_df = spark.table(\"default.exchange\")\n",
    "\n",
    "# Define the target date\n",
    "target_date = '2020-01-28'\n",
    "\n",
    "# Filter recurring items and join tables\n",
    "recurring_items = (\n",
    "    product_item_df\n",
    "    .filter(col(\"type\") == \"recurring\")  # Only recurring items\n",
    "    .join(billing_df, product_item_df.billing_id == billing_df.id)  # Join with Billing\n",
    "    .join(exchange_df, \n",
    "          (billing_df.currency == exchange_df.from_currency) & \n",
    "          (billing_df.invoice_date == exchange_df.date))  # Join with Exchange\n",
    "    .filter((col(\"valid_from\") <= target_date) & (col(\"valid_to\") >= target_date))  # Valid on the target date\n",
    ")\n",
    "\n",
    "# Calculate days of validity and ARR in USD\n",
    "arr_usd = (\n",
    "    recurring_items\n",
    "    .withColumn(\"days_validity\", datediff(col(\"valid_to\"), col(\"valid_from\")))  # Calculate days of validity\n",
    "    .withColumn(\"annualized_revenue\", \n",
    "                (col(\"amount\") / col(\"days_validity\")) * 360 * col(\"exchange_rate\"))  # Calculate ARR\n",
    "    .filter(col(\"billing_type\") == \"invoice\")  # Only include invoices\n",
    "    .agg(round(spark_sum(\"annualized_revenue\"), 2).alias(\"ARR_USD\"))  # Sum up ARR and round to 2 decimal places\n",
    ")\n",
    "\n",
    "# Display the result\n",
    "arr_usd.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annual Recurring Revenue (ARR) for the last day of each month between June and December 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import col, datediff, round, sum as spark_sum, sequence, last_day, lit, explode\n",
    "\n",
    "# Load the Delta tables\n",
    "billing_df = spark.table(\"default.billing\")  # Adjust database.table name if necessary\n",
    "product_item_df = spark.table(\"default.product_items\")  # Adjust database.table name\n",
    "exchange_df = spark.table(\"default.exchange\")  # Adjust database.table name\n",
    "\n",
    "# Generate the sequence of dates (from June 2019 to December 2019)\n",
    "date_sequence = spark.sql(\"SELECT SEQUENCE(DATE('2019-06-01'), DATE('2019-12-01'), INTERVAL 1 MONTH) AS month_start\")\n",
    "\n",
    "# Explode the sequence and get the last day of each month\n",
    "date_range = (\n",
    "    date_sequence\n",
    "    .withColumn(\"month_start\", explode(col(\"month_start\")))  # Explode the sequence into individual rows\n",
    "    .withColumn(\"arr_date\", last_day(col(\"month_start\")))  # Get the last day of each month\n",
    "    .select(\"arr_date\")\n",
    ")\n",
    "\n",
    "# Filter recurring items and join tables\n",
    "recurring_items = (\n",
    "    product_item_df\n",
    "    .filter(col(\"type\") == \"recurring\")  # Only recurring items\n",
    "    .join(billing_df, product_item_df.billing_id == billing_df.id)  # Join with Billing\n",
    "    .join(exchange_df, \n",
    "          (billing_df.currency == exchange_df.from_currency) & \n",
    "          (billing_df.invoice_date == exchange_df.date))  # Join with Exchange\n",
    ")\n",
    "\n",
    "# Calculate ARR for each month\n",
    "monthly_arr = (\n",
    "    recurring_items\n",
    "    .crossJoin(date_range)  # Combine with all months\n",
    "    .filter((col(\"valid_from\") <= col(\"arr_date\")) & (col(\"valid_to\") >= col(\"arr_date\")))  # Valid on arr_date\n",
    "    .withColumn(\"days_validity\", datediff(col(\"valid_to\"), col(\"valid_from\")))  # Calculate days of validity\n",
    "    .withColumn(\"annualized_revenue\", \n",
    "                (col(\"amount\") / col(\"days_validity\")) * 360 * col(\"exchange_rate\"))  # Calculate ARR\n",
    "    .filter(col(\"billing_type\") == \"invoice\")  # Only include invoices\n",
    "    .groupBy(\"arr_date\")  # Group by month\n",
    "    .agg(round(spark_sum(\"annualized_revenue\"), 2).alias(\"ARR_USD\"))  # Sum ARR for the month\n",
    "    .orderBy(\"arr_date\")\n",
    ")\n",
    "\n",
    "# Display the result\n",
    "monthly_arr.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
